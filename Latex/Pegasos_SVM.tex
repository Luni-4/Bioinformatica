% Preambolo
\include{preamble}

\usepackage{afterpage}

% Definizione della cartella contenente le immagini da usare
\graphicspath{{../img/}}

% //////////////////// DOCUMENTO /////////////////

\begin{document}

% //////////////////// Titolo /////////////////

%Titolo e intestazione
\title{% 
        Predizione della funzione delle proteine \\
        con metodi di Machine Learning}
  
\author{Michele Valsesia}

\date{Anno accademico 2017/2018} 

\maketitle

\tableofcontents

% //////////////////// Capitoli /////////////////

\newpage

\section*{Introduzione}
Il progetto ambisce ad utilizzare degli algoritmi di apprendimento automatico per costruire dei classificatori in grado di predire la funzione delle proteine della \textit{Drosophila melanogaster} (moscerino della frutta), organismo modello per gli insetti. Un ulteriore obiettivo è dato dall'analisi del comportamento e delle performance di ciascuno dei classificatori prodotti.

Per affrontare il problema si è puntato su modelli semplici, rapidi, che consentano di ottenere una buona valutazione dell'errore di classificazione. Gli algoritmi di apprendimento scelti sono: 

\begin{itemize}
    \item Support Vector Machine (SVM)    
    \item Pegasos
\end{itemize}

Ognuno dei metodi sopra elencati verrà applicato alla predizione dei termini CC (Cellular Component) della GO (Gene Ontology).

\paragraph*{}
Il progetto è stato implementato utilizzando \textit{Python} 3.5 e la versione 0.18.1 della libreria per l'apprendimento automatico \textit{scikit-learn}. Le strutture dati realizzate sfruttano la libreria \textit{SciPy} 0.19.1.

\paragraph*{}
L'elaborato descrive i passaggi e le problematiche affrontate durante lo svolgimento del lavoro. Si è deciso di associare ad ogni singolo stadio lavorativo un capitolo. 

Il \autoref{chap:dati} analizza i dati di input, mostra la loro struttura e le possibili metodologie di elaborazione. 

Il \autoref{chap:metodi} spiega i metodi di machine learning scelti, la loro implementazione pratica e i settaggi utilizzati.

Il \autoref{chap:risultati} illustra i risultati ottenuti dai classificatori per mezzo di grafici e confronta tra loro i diversi algoritmi di apprendimento, allo scopo di individuare quelli con il più basso errore di classificazione.

% Analisi dei dati
\include{data}

\chapter{Metodi di Machine Learning} 
\label{chap:metodi}

I metodi di Machine Learning scelti si basano su modelli semplici, rapidi, che consentono di ottenere una buona valutazione dell'errore di classificazione. Gli algoritmi di apprendimento considerati sono le \textit{Support Vector Machine (SVM)} ed una loro particolare istanza chiamata \textit{Pegasos}. Analizzando le differenze tra i vari modelli si vuole decretare l'algoritmo di apprendimento migliore.

\paragraph*{}
Per poter effettuare il tuning degli iperparametri, sono state create diverse configuarazioni di esecuzione.
Le configurazioni sono inserite in un dizionario Python che ha come chiavi i nomi delle configurazioni stesse e come oggetti i classificatori della liberia scikit-learn con impostati i parametri che si vogliono testare.
Utilizzando tutte le classi si ottiene un elevato tempo computazionale per ciascuna configurazione. Per evitare ciò, si è deciso di campionare le classi, prendendone una ogni cinque.

\section{Support Vector Machine}
Una \textit{Support Vector Machine}, comunemente abbreviata in \textit{SVM}, costruisce un iperpiano, o una serie di iperpiani, in uno spazio iperdimensionale, in modo da poter risolvere problemi di classificazione e di regressione. Una buona separazione dei dati si verifica quando si ottiene un iperpiano che massimizza la distanza dal più vicino esempio di ogni classe, in altro modo, quando si individua l'iperpiano di margine massimo. In generale, più è ampio il margine, più l'errore di classificazione sarà basso.

SVM ricava l'iperpiano di margine massimo risolvendo il seguente problema di ottimizzazione lineare convessa

\begin{equation} \label{uno}
\begin{split}
\min_ {w, b, \zeta} \frac{1}{2} w^T w + C \sum_{i=1}^{n} \zeta_i \\
\textrm {subject to } & y_i (w^T \phi (x_i) + b) \geq 1 - \zeta_i, \\
& \zeta_i \geq 0, i=1, \dotsc ,n
\end{split}
\end{equation}

La sua funzione di decisione è definita come:

\begin{equation} \label{due}
\sgn(\sum_{i=1}^n y_i \alpha_i K(x_i, x) + \rho)
\end{equation}

I support vectors sono gli esempi del training set che, a seconda dell'iperpiano ottenuto, hanno un margine inferiore o pari a 1. La soluzione prodotta da SVM dipende solo da questi esempi.

\paragraph*{}
L'apprendimento del classificatore è stato effettuato usando la funzione \textit{SVC}, implementata nel modulo \textit{sklearn.svm} contenente gli algoritmi SVM della libreria scikit-learn. Nella definizione del metodo sono stati impostati i seguenti parametri:

\paragraph*{}
\textbf{\textit{C}}. Penalità sull'errore commesso. Un valore elevato di C crea un modello complesso che mira a classificare nel miglior modo possibile gli esempi del training set, ma al tempo stesso aumenta notevolmente la varianza e può portare ad overfitting. L'uso di un valore piccolo, al contrario, costruisce un modello più semplice e con una varianza più bassa. È un valore di tipo float. 

\paragraph*{}
\textbf{\textit{Kernel}}. Specifica il kernel che deve essere usato dall'algoritmo. I kernel scelti per lo svolgimento del progetto sono stati:

\begin{itemize}
    \item Radial Basis Function (RBF) 
    \item Polinomiale
\end{itemize}

\paragraph*{}
\textbf{\textit{degree}}. Grado del polinomio usato dal Kernel Polinomiale. È un valore intero.

\paragraph*{}
\textbf{\textit{gamma}}. $\gamma = \dfrac{1}{\sigma}$. Definisce l'ampiezza delle Gaussiane nello spazio RBF. SVM è molto sensibile a questo parametro. Un valore elevato di gamma comporta delle Gaussiane molto strette e ogni esempio non è influenzato da quelli vicini, quindi il numero di support vectors sarà basso, ma si rischia di incorrere nell'overfitting. Al contrario, un valore molto piccolo di gamma porterà ad avere delle Gaussiane molto ampie, perciò un esempio verrà influenzato dagli esempi del training set circostanti e la quantità di support vectors risulterà elevata. Un gamma troppo piccolo ammetterebbe come support vectors tutti gli esempi e il modello creato non riuscirebbe a discriminare al meglio le classi. È un valore di tipo float.

\paragraph*{}
\textbf{\textit{class\_weight}}. Parametro utilizzato per il bilanciamento di classi sbilanciate. Se non viene fornito in input, tutte le classi hanno peso unitario. Il peso di ciascuna classe può essere tarato, a seconda del risultato che si vuole ottenere, privilegiando una classe rispetto ad un'altra, oppure calcolato in maniera autonoma dalla funzione per mezzo della modalità \say{balanced}. 
Questa modalità sfrutta i valori delle etichette di una classe per aggiustare i pesi in maniera tale che risultino inversamente proporzionali alle frequenze delle classi di input. In pratica, una classe con una cardinalità molto bassa, avrà un peso alto, al contrario, una classe con cardinalità elevata avrà un peso più basso. La regola di assegnamento dei pesi è la seguente.

\begin{center}
numero\_campioni / (numero\_classi * array\_contenente\_cardinalità\_classi)
\end{center}


\subsection{Parametri}
Per determinare con quali parametri, sul dataset considerato, la SVM produce dei buoni risultati, vengono eseguite le seguenti configurazioni:

\paragraph*{}
\textbf{\textit{Unbalanced}}. Il kernel di questa configurazione è RBF. La funzione SVC viene eseguita con i parametri di default, C unitario e gamma variabile, per determinare se è necessaria un'eventuale modifica degli iperparametri.

\paragraph*{}
\textbf{\textit{Balanced}}. Questa configurazione utilizza gli stessi parametri della Unbalanced, ma imposta il parametro class\_weight a \say{balanced} per poter bilanciare le classi.

\paragraph*{}
\textbf{\textit{C e gamma variabili}}. Si hanno due configurazioni con queste caratteristiche. Il kernel usato in entrambe è RBF. Per la prima configurazione, il parametro C di SVC assume un valore elevato, mentre gamma uno molto piccolo. La seconda configurazione fa crescere di un ordine di grandezza entrambi i valori.

\paragraph*{}
\textbf{\textit{Poly}}. Viene usato un kernel polinomiale di grado 4. Il valore di class\_weight è \say{balanced}. Tutti i restanti parametri non sono stati modificati. La scelta del grado del polinomio è stata effettuata tenendo in considerazione la potenza computazionale delle macchine a disposizione.

\begin{table}[ht]%	
\centering
\caption{Configurazioni di SVM}\label{tab:b2}
\begin{tabular}{|c|c|c|S[table-parse-only = true]|S[table-parse-only = true]|c|}
\hline
Nome                    & Bilanciamento & Kernel & C        & Gamma & Degree    \\ 
\hline 
SVM\_Unbalanced         & -             & RBF    & 1.0      & auto    & -       \\
\hline 
SVM\_Balanced           & balanced      & RBF    & 1.0      & auto    & -       \\
\hline 
SVM\_Balanced\_C7\_G7   & balanced      & RBF    & 1.0e+05  & 0.01    & -       \\
\hline 
SVM\_Balanced\_C8\_G8   & balanced      & RBF    & 1.0e+06  & 0.1     & -       \\
\hline 
SVM\_Balanced\_Poly\_4  & balanced      & Poly   & 1.0      & auto    & 4       \\
\hline 
\end{tabular} 
\end{table}

\section{Pegasos}
Pegasos è un algoritmo di apprendimento iterativo utilizzato per risolvere il problema di ottimizzazione lineare convessa posto dalle Support Vector Machines (SVM).
È una particolare istanza di OGD e dipende da due parametri fondamentali:

\paragraph*{}
\textbf{\textit{T}}. Numero di cicli. Determina il numero di iterazioni compiute dall'algoritmo. Questo valore corrisponde anche alla totalità degli esempi estratti uniformemente dal training set. Assume solo valori interi.

\paragraph*{}
$\mathbf{\mathit{\lambda}}$. Coefficiente di regolarizzazione. Viene usato per calcolare il costo di misclassificazione $\eta_t$, infatti $\eta_t = \dfrac{1}{\lambda t}$, con $t$ pari al ciclo corrente. Un $\lambda$ basso comporta un costo elevato e dei pesi sempre maggiori all'aumentare del numero di iterazioni, al contrario, un alto valore di $\lambda$ mantiene bassi i pesi dando poca importanza all'errore di classificazione commesso. Assume valori decimali.

\paragraph*{}
L'analisi di Pegasos è stata effettuata usando due implementazioni diverse. La prima è stata scritta interamente in Python, mentre la seconda utilizza la funzione \textit{SGDClassifier} della libreria scikit-learn.
La funzione \textit{SGDClassifier} sfrutta il parametro \textit{class\_weight} per il bilanciamento delle classi, descritto precedentemente in SVM.  

\subsection{Parametri}
Le diverse configurazioni di Pegasos si differenziano tra loro per i valori di T e $\lambda$ e, tranne una, si riferiscono tutte alla prima implementazione. Per la seconda implementazione, si è usata un'unica configurazione e con un valore di $\lambda$ non molto piccolo, a causa dell'elevato tempo computazionale richiesto dalla funzione della libreria di scikit-learn. Si è comunque deciso di tenerla in considerazione in modo da poterla confrontare con le altre.

\paragraph*{}
Si è variato principalmente il parametro $\lambda$. Per la maggior parte delle configurazioni, si è mantenuto T costante perché, per valori sufficientemente alti, non influenza notevolmente i risultati prodotti dall'algoritmo. La Tabella~\ref{tab:b3} mostra le varie configurazioni usate. L'ultima riga è l'unica configurazione relativa alla seconda implementazione.

\begin{table}[ht]%	
\centering
\caption{Configurazioni di Pegasos}\label{tab:b3}
\begin{tabular}{|c|c|S[table-parse-only = true]|S[table-parse-only = true]|}
\hline
Nome                 & Bilanciamento &  T       & $\lambda$ \\
\hline 
Pegasos\_Default     & -             & 1000     & 0.05      \\
\hline 
Pegasos\_I0\_L0      & -             & 1e+04    & 1.0e-04   \\
\hline 
Pegasos\_I9\_L9      & -             & 1e+05    & 1.0e-05   \\
\hline 
Pegasos\_I9\_L1\_0   & -             & 1e+05    & 1.0e-10   \\
\hline 
Pegasos\_I9\_L1\_1   & -             & 1e+05    & 1.0e-11   \\
\hline 
Pegasos\_I0\_L1\_5   & -             & 1e+04    & 1.0e+6    \\
\hline 
Pegasos\_I9\_L1\_2   & -             & 1e+05    & 2.0       \\
\hline 
Pegasos\_I9\_L1\_3   & -             & 1e+05    & 100.0     \\
\hline 
Pegasos\_I9\_L1\_4   & -             & 1e+05    & 1000.0    \\
\hline 
Pegasos\_SGD         & balanced      & 1e+04    & 1.0e-11   \\
\hline 
\end{tabular} 
\end{table}

\newpage

% Costruzione del software
\include{software}

% Metriche
\include{metrics}

\section{Risultati}

\subsection{Ill-defined}
Durante la fase di cross-validation, è emerso che parte dei classificatori addestrati non sono riusciti a predire nessun esempio del test set, dando solo risposte negative. Poichè i 5 fold sono stati costruiti in modo da avere sempre almeno un esempio positivo, questo significa che il classificatore ha commesso un errore.

Non avendo predetto neanche un positivo (vero o falso che sia), il classificatore ha imparato a rispondere negativamente a qualunque input, rendendosi di fatto inutilizzabile.

Inoltre, poichè non si ha nessuna predizione positiva, il calcolo della Precision contiene una divisione per zero e quindi risulta impossibile. Di conseguenza anche la F-score non è computabile. Le funzioni della libreria scikit-learn rimediano parzialmente a questo comportamento ponendo a zero le metriche problematiche e catalogandole come \emph{ill-defined}.

Durante l'analisi delle metriche è possibile selezionare i predittori intrinsecamente difettosi, individuando quelli con Precision e F-score uguale a zero. In questo modo, risulta più facile quantificarne il loro numero.

Si osserva che il numero di predittori \emph{ill-defined} aumenta in presenza di training set sbilanciati. Ovviamente anche l'algoritmo di apprendimento influisce notevolmente sulla qualità dei risultati: se le classi non vengono bilanciate, i predittori generati saranno difettosi.

Il sistema 5-fold prevede che per ogni classe dell'ontologia vengano generati 5 distinti predittori. I predittori \emph{ill-defined} possono essere numerosi, ma fintantochè una classe possiede almeno un predittore non \emph{ill-defined}, è possibile costruire, per tale classe, un predittore funzionante.

Il numero di predittori \emph{ill-defined} può essere considerato un indicatore di qualità dell'algoritmo di apprendimento. A parità di cardinalità della classe, avere un numero minore di \emph{ill-defined} comporta un utilizzo migliore degli esempi positivi.

Gli \emph{ill-defined} di SVM, mostrati dalla Figura~\ref{figure:ill12}, non presentano variazioni significative ed il valor medio, in alcune configurazioni, rimane costante a 2.

In Pegasos, come si vede dalla Figura~\ref{figure:ill13}, il numero di ill-defined è elevatissimo per quasi tutte le configurazioni, fatta eccezione per \say{Pegasos\_SGD} che non ne produce nessuno. Questa notevole differenza è dovuta al mancato utilizzo di una tecnica per il bilanciamento delle classi nella prima implementazione.

I classificatori difettosi sono inutilizzabili, ma facili da identificare ed escludere. Pertanto, nelle analisi che seguono, si è filtrato il bias introdotto dai classificatori \emph{ill-defined} e si sono analizzati solo classificatori costruiti correttamente.

\subsection{Analisi a Livelli}
Per identificare i migliori classificatori e poterli confrontare tra loro, è stata creata una struttura a tre livelli.

Al \textit{Livello 1} vengono confrontate le metriche prodotte dalle diverse configurazioni di uno stesso classificatore. Questo metodo consente di determinare qual è il migliore classificatore per ogni famiglia di modelli. La Figura~\ref{figure:liv1.2} mette in relazione tra loro le diverse configurazioni di SVM, mentre la Figura~\ref{figure:liv1.3} quelle di Pegasos.

\paragraph*{}
Il \textit{Livello 2} confronta la configurazione del classificatore che ha ottenuto i risultati migliori al livello precedente su diverse classi. Lo scopo di questa analisi consiste nel capire come un classificatore varia le sue predizioni a seconda della classe scelta. Le classi considerate sono tre e sono disposte in ordine crescente rispetto al numero di esempi positivi. L'id della classe è dato dall'unione tra il nome dell'ontologia e la relativa colonna della Matrice delle Annotazioni.
La Figura~\ref{fig:liv2} mostra le metriche ottenute dalle migliori configurazioni di SVM e Pegasos.

\paragraph*{}
Il \textit{Livello 3} mette in relazione tra loro le migliori configurazioni dei classificatori di ogni famiglia di modelli. Le metriche considerate sono Recall, AUROC, AUPRC e F-score. La Figura~\ref{fig:liv3} mostra il confronto tra SVM e Pegasos.

\subsection{Risultati di SVM}
Le migliori configurazioni di SVM sono la \say{SVM\_Balanced\_C7\_G7} e la \\ \say{SVM\_Balanced\_C8\_G8}. Entrambe utilizzano un kernel RBF, hanno un valore di C molto grande ed un gamma piccolo. La F-score è ben al di sopra della media, con valori di Precision e Recall notevoli. 

La \say{SVM\_Balanced\_Poly\_4}, nonostante facesse uso di un kernel polinomiale di 4 grado, ha prodotto scarsi risultati al costo di un elevato tempo computazionale.

\subsection{Risultati di Pegasos}
Come si può notare dai risultati mostrati dalla Figura~\ref{figure:liv1.3}, tutte le configurazioni di Pegasos producono pessimi risultati. La principale causa è data dalla presenza di un gran numero di classi non linearmente separabili, che non consentono di trovare un iperpiano che separi perfettamente gli esempi, inoltre la prima implementazione non presenta un meccanismo per il bilanciamento delle classi, per cui il numero di ill-defined risulta molto alto.

\paragraph*{}
\say{Pegasos\_SGD} è l'unico classificatore senza ill-defined e ciò si deve all'utilizzo del parametro \say{balanced}.

\say{Pegasos\_I0\_L1\_5}, \say{Pegasos\_I9\_L1\_2}, \say{Pegasos\_I9\_L1\_3}, \say{Pegasos\_I9\_L1\_4} sono le configurazioni migliori e hanno gli stessi valori in ciascuna metrica, ma non vengono valutate a causa del loro elevatissimo numero di ill-defined. Per l'analisi del \textit{Livello 2} e del \textit{Livello 3} viene usato \say{Pegasos\_I9\_L1\_1}. I risultati prodotti da questo classificatore non sono per nulla buoni, ma i suoi ill-defined sono minori in confronto a quelli delle restanti configurazioni. Dal confronto effettuato ai livelli successivi, si evince subito che le sue prestazioni sono nettamente inferiori rispetto a quelle degli altri classificatori.
Uno sviluppo ulteriore potrebbe esssere dato dall'utilizzo di funzioni kernel sia per la prima che per la seconda implementazione, in modo da poter migliorare le performance generali.

\paragraph*{}
Le brutte prestazioni di Pegasos hanno comportato un'analisi più approfondita del classificatore utilizzando solo le classi linearmente separabili dell'ontologia CC.
La Figura~\ref{figure:ill14} mostra la quantità di ill-defined prodotti. Come si può notare, le configurazioni \say{Pegasos\_I9\_L1\_0} e \say{Pegasos\_I9\_L1\_1}, riferite alla prima implementazione, non hanno ill-defined. Questo risultato sancisce che valori piccoli di $\lambda$ producono buoni risultati su classi linearmente separabili sbilanciate. Anche la configurazione \say{Pegasos\_SGD} ha un numero di ill-defined pari a 0, ma bisogna ricordare che la seconda implementazione usa un parametro per bilanciare le classi.

\paragraph*{}
Il confronto tra le varie configurazioni di Pegasos è illustrato dalla Figura~\ref{figure:illps}. \say{Pegasos\_I9\_L1\_0} e \say{Pegasos\_I9\_L1\_1} ottengono risultati identici. Le differenze tra le loro $\lambda$ è di un ordine di grandezza, per cui per valori troppo piccoli l'algoritmo pone un limite inferiore. La F-score risulta la migliore rispetto a quella delle restanti configurazioni, ma la Precision assume un valore troppo basso. \say{Pegasos\_SGD} ottiene risultati inferiori e questo è dovuto all'uso di un $\lambda$ abbastanza grande, necessario per ridurre i tempi di computazione della seconda implementazione.

% //////////////////// ILL-DEFINED /////////////////

\newpage

\topskip0pt
\vspace*{\fill}

\begin{figure}[hb]%
    \centering
    \includegraphics[scale = 0.80]{CC-SVM-ills}%   
    \caption{Numero di ill-defined delle configurazioni di SVM}%
    \label{figure:ill12}%
\end{figure}

\vspace*{\fill}

\clearpage

\topskip0pt
\vspace*{\fill}

\begin{figure}[hpt!]%
    \centering
    \includegraphics[scale = 0.80]{CC-Pegasos-ills}%   
    \caption{Numero di ill-defined delle configurazioni di Pegasos}%
    \label{figure:ill13}%
\end{figure}

\begin{figure}[hbp!]%
    \centering
    \includegraphics[scale = 0.80]{CC-Pegasos-ills-LS}%   
    \caption{Numero di ill-defined delle configurazioni di Pegasos su classi linearmente separabili}%
    \label{figure:ill14}%
\end{figure}

\vspace*{\fill}

% //////////////////// LIVELLO 1 /////////////////

\topskip0pt
\vspace*{\fill}

\begin{figure}[hb]%
    \centering
    \includegraphics[scale = 0.80]{CC-SVM-level1}%   
    \caption{Confronto tra le metriche di diverse configurazioni di SVM}%
    \label{figure:liv1.2}%
\end{figure}

\vspace*{\fill}

\topskip0pt
\vspace*{\fill}

\begin{figure}[hb]%
    \centering
    \includegraphics[scale = 0.80]{CC-Pegasos-level1}%   
    \caption{Confronto tra le metriche di diverse configurazioni di Pegasos}%
    \label{figure:liv1.3}%
\end{figure}

\vspace*{\fill}


% //////////////////// LIVELLO 2 /////////////////

\topskip0pt
\vspace*{\fill}

\begin{figure}[ht]%
    \centering
    \includegraphics[scale = 0.80]{CC-level2}%
    \caption{Confronto tra i classificatori con le migliori performance su diverse classi}%
    \label{fig:liv2}% 
\end{figure}

\vspace*{\fill}


% //////////////////// LIVELLO 3 /////////////////

\topskip0pt
\vspace*{\fill}

\begin{figure}[ht]%
    \centering
    \includegraphics[scale = 0.80]{CC-level3}%
    \caption{Confronto tra i migliori classificatori delle diverse famiglie di modelli}%
    \label{fig:liv3} 
\end{figure}

\vspace*{\fill}

% //////////////////// PEGASOS LINEARMENTE SEPARABILE /////////////////

\topskip0pt
\vspace*{\fill}

\begin{figure}[hb]%
    \centering
    \includegraphics[scale = 0.80]{CC-Pegasos-level1-LS}%   
    \caption{Confronto tra le metriche di diverse configurazioni di Pegasos su classi linearmente separabili}%
    \label{figure:illps}%
\end{figure}

\vspace*{\fill}

\end{document}